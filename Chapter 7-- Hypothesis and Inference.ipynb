{
 "metadata": {
  "name": "Chapter 7-- Hypothesis and Inference"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Statistical Hypothesis Testing"
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": "Often, as data scientists, we\u2019ll want to test whether a certain hypothesis is likely to be true.\nFor our purposes, hypotheses are assertions like \u201cthis coin is fair\u201d or \u201cdata scientists prefer\nPython to R\u201d or \u201cpeople are more likely to navigate away from the page without ever\nreading the content if we pop up an irritating interstitial advertisement with a tiny, hard-tofind\nclose button\u201d that can be translated into statistics about data. Under various\nassumptions, those statistics can be thought of as observations of random variables from\nknown distributions, which allows us to make statements about how likely those\nassumptions are to hold"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import math",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Example: Flipping a Coin"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#From Chapter 6\ndef inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):\n    \"\"\"find approximate inverse using binary search\"\"\"\n    # if not standard, compute standard and rescale\n    if mu != 0 or sigma != 1:\n        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n    low_z, low_p = -10.0, 0 # normal_cdf(-10) is (very close to) 0\n    hi_z, hi_p = 10.0, 1 # normal_cdf(10) is (very close to) 1\n    while hi_z - low_z > tolerance:\n        mid_z = (low_z + hi_z) / 2 # consider the midpoint\n        mid_p = normal_cdf(mid_z) # and the cdf's value there\n        if mid_p < p:\n        # midpoint is still too low, search above it\n            low_z, low_p = mid_z, mid_p\n        elif mid_p > p:\n            # midpoint is still too high, search below it\n            hi_z, hi_p = mid_z, mid_p\n        else:\n            break\n    return mid_z\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def normal_cdf(x,mu=0,sigma=1):\n    return (1+math.erf((x-mu)/math.sqrt(2)/sigma))/2",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def normal_approximation_to_binomial(n,p):\n    \"\"\"finds mu and sigma corresponding to a Binomial(n, p)\"\"\"\n    mu=p*n\n    sigma=math.sqrt(p*(1-p)*n)\n    return mu,sigma",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# the normal cdf _is_ the probability the variable is below a threshold\nnormal_probability_below=normal_cdf   ",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# the normal cdf _is_ the probability the variable is below a threshold\ndef normal_probability_above(lo,mu=0,sigma=1):\n    return 1-normal_cdf(lo,mu,sigma)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# it's between if it's less than hi, but not less than lo\ndef normal_approximation_between(lo,hi,mu,sigma):\n    return normal_cdf(hi,mu,sigma)-normal_cdf(lo,mu,sigma)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# it's outside if it's not between\ndef normal_probability_outside(lo,hi,mu=0,sigma=1):\n    return 1-normal_probability_between(lo,hi,mu,sigma)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": "We can also do the reverse \u2014 find either the nontail region or the (symmetric) interval\naround the mean that accounts for a certain level of likelihood. For example, if we want to\nfind an interval centered at the mean and containing 60% probability, then we find the\ncutoffs where the upper and lower tails each contain 20% of the probability (leaving 60%):"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def normal_upper_bound(probability,mu=0,sigma=1):\n    \"\"\"returns the z for which P(Z <= z) = probability\"\"\"\n    return inverse_normal_cdf(probability,mu,sigma)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def normal_lower_bound(probability,mu=0,sigma=1):\n    \"\"\"returns the z for which P(Z >= z) = probability\"\"\"\n    return inverse_normal_cdf(1-probability,mu,sigma)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def normal_two_sided_bounds(probability,mu=0,sigma=1):\n    \"\"\"returns the symmetric (about the mean) bounds \n            that contain the specified probability\"\"\"\n    tail_probability=(1-probability)/2\n\n    # upper bound should have tail_probability above it\n    upper_bound=normal_lower_bound(tail_probability,mu,sigma)\n    # lower bound should have tail_probability below it\n    lower_bound=normal_upper_bound(tail_probability,mu,sigma)\n    return lower_bound,upper_bound",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "mu_0,sigma_0=normal_approximation_to_binomial(1000,.5)\nprint mu_0,sigma_0",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "500.0 15.8113883008\n"
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "normal_two_sided_bounds(.95,mu_0,sigma_0)\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": "(469.01026640487555, 530.9897335951244)"
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# 95% bounds based on assumption p is 0.5\nlo,hi=normal_two_sided_bounds(.95,mu_0,sigma_0)\nprint lo,hi",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "469.010266405 530.989733595\n"
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# actual mu and sigma based on p = 0.55\nmu_1,sigma_1=normal_approximation_to_binomial(1000,.55)\nprint mu_1,sigma_1",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "550.0 15.7321327226\n"
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# a type 2 error means we fail to reject the null hypothesis\n# which will happen when X is still in our original interval\ntype_2_probability=normal_approximation_between(lo,hi,mu_1,sigma_1)\npower=1-type_2_probability\nprint power",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0.886548001295\n"
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "hi=normal_upper_bound(.95,mu_0,sigma_0)\nprint hi",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "526.007358524\n"
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "type_2_probability=normal_probability_below(hi,mu_1,sigma_1)\nprint type_2_probability",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0.0636205196693\n"
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "power=1-type_2_probability\nprint power",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0.936379480331\n"
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def two_sided_p_value(x,mu=0,sigma=1):\n    if x>=mu: # if x is greater than the mean, the tail is what's greater than x\n        return 2*normal_probability_above(x,mu,sigma)\n    else: # if x is less than the mean, the tail is what's less than x\n        return 2*normal_probability_below(x,mu,sigma)\n    ",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "two_sided_p_value(529.5,mu_0,sigma_0)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": "0.06207721579598857"
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": "NOTE\nWhy did we use 529.5 instead of 530? This is what\u2019s called a continuity correction. It reflects the fact that\nnormal_probability_between(529.5, 530.5, mu_0, sigma_0) is a better estimate of the probability of\nseeing 530 heads than normal_probability_between(530, 531, mu_0, sigma_0) is.\nCorrespondingly, normal_probability_above(529.5, mu_0, sigma_0) is a better estimate of the\nprobability of seeing at least 530 heads. You may have noticed that we also used this in the code that\nproduced Figure 6-4."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import random\nextream_value_count=0\nfor _ in range(10000):\n    num_heads=sum(1 if random.random()<.5 else 0\n                  for _ in range(1000))\n    if num_heads>=530 or num_heads<=470:\n        extream_value_count+=1\n\nprint extream_value_count/10000",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0\n"
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": "Since the p-value is greater than our 5% significance, we don\u2019t reject the null. If we\ninstead saw 532 heads, the p-value would be:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "two_sided_p_value(531.5,mu_0,sigma_0)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": "0.046345287837786575"
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "upper_p_value=normal_probability_above\nprint upper_p_value\nlower_p_value=normal_probability_below\nprint lower_p_value",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "<function normal_probability_above at 0x05BD27B0>\n<function normal_cdf at 0x03053B70>\n"
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "upper_p_value(524.5,mu_0,sigma_0)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": "0.06062885772582083"
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "upper_p_value(526.5,mu_0,sigma_0)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": "0.04686839508859242"
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Confidence Intervals\n"
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": "We\u2019ve been testing hypotheses about the value of the heads probability p, which is a\nparameter of the unknown \u201cheads\u201d distribution. When this is the case, a third approach is\nto construct a confidence interval around the observed value of the parameter.\nFor example, we can estimate the probability of the unfair coin by looking at the average\nvalue of the Bernoulli variables corresponding to each flip \u2014 1 if heads, 0 if tails. If we\nobserve 525 heads out of 1,000 flips, then we estimate p equals 0.525.\nHow confident can we be about this estimate? Well, if we knew the exact value of p, the\ncentral limit theorem (recall \u201cThe Central Limit Theorem\u201d) tells us that the average of\nthose Bernoulli variables should be approximately normal, with mean p and standard\ndeviation:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "math.sqrt(p*(1-p)/1000)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'p' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-82-380468ecfc52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import math\np_hat = (525.0/ 1000)\nmu = p_hat\nsigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\nprint sigma",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0.0157916116974\n"
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "normal_two_sided_bounds(0.95, mu, sigma)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": "(0.4940490278129096, 0.5559509721870904)"
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "p_hat = 540.0 / 1000\nmu = p_hat\nsigma = math.sqrt(p_hat * (1 - p_hat) / 1000) # 0.0158\nprint normal_two_sided_bounds(0.95, mu, sigma) # [0.5091, 0.5709]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "(0.5091095927295919, 0.5708904072704082)\n"
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "P-hacking"
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": "A procedure that erroneously rejects the null hypothesis only 5% of the time will \u2014 by\ndefinition \u2014 5% of the time erroneously reject the null hypothesis:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def run_experiment():\n    \"\"\"flip a fair coin 1000 times, True = heads, False = tails\"\"\"\n    return[random.random()<.5 for _ in range(1000)]",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def reject_fairness(experiment):\n    \"\"\"using the 5% significance levels\"\"\"\n    num_heads=len([flip for flip in experiment if flip])\n    return num_heads<469 or num_heads>531\n\nrandom.seed(0)\nexperiments=[run_experiment() for _ in range(1000)]\nnum_rejections=len([experiment for experiment in experiments\n                        if reject_fairness(experiment)])\nprint num_rejections",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "46\n"
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Example: Running an A/B Test\nOne of your primary responsibilities at DataSciencester is experience optimization, which\nis a euphemism for trying to get people to click on advertisements. One of your advertisers\nhas developed a new energy drink targeted at data scientists, and the VP of\nAdvertisements wants your help choosing between advertisement A (\u201ctastes great!\u201d) and\nadvertisement B (\u201cless bias!\u201d).\nBeing a scientist, you decide to run an experiment by randomly showing site visitors one\nof the two advertisements and tracking how many people click on each one.\nIf 990 out of 1,000 A-viewers click their ad while only 10 out of 1,000 B-viewers click\ntheir ad, you can be pretty confident that A is the better ad. But what if the differences are\nnot so stark? Here\u2019s where you\u2019d use statistical inference"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def estimated_parameters(N,n):\n    p=n/N\n    sigma=math.sqrt(p+(1-p)/N)\n    return p,sigma",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def a_b_test_statistic(N_A, n_A, N_B, n_B):\n    p_A, sigma_A = estimated_parameters(N_A, n_A)\n    p_B, sigma_B = estimated_parameters(N_B, n_B)\n    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "z = a_b_test_statistic(1000.0, 200.0, 1000.0, 180.0)\nprint z",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "-0.0323753470125\n"
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "two_sided_p_value(z)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": "0.9741727224134493"
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Bayesian Inference"
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": "The procedures we\u2019ve looked at have involved making probability statements about our\ntests: \u201cthere\u2019s only a 3% chance you\u2019d observe such an extreme statistic if our null\nhypothesis were true.\u201d\nAn alternative approach to inference involves treating the unknown parameters themselves\nas random variables. The analyst (that\u2019s you) starts with a prior distribution for the\nparameters and then uses the observed data and Bayes\u2019s Theorem to get an updated\nposterior distribution for the parameters. Rather than making probability judgments about\nthe tests, you make probability judgments about the parameters themselves.\nFor example, when the unknown parameter is a probability (as in our coin-flipping\nexample), we often use a prior from the Beta distribution, which puts all its probability\nbetween 0 and 1:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def B(alpha,beta):\n    \"\"\"a normalizing constant so that the total probability is 1\"\"\"\n    return math.gamma(alpha)*math.gamma(beta)/math.gamma(alpha+beta)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def beta_pdf(x,alpha,beta):\n    if x<0 or x>1:\n        return 0\n    return x**(alpha-1)*(1-x)**(beta-1)/B(alpha,be)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}